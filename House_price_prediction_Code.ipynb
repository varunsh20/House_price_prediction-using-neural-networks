{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras import models\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Train_Data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100 entries, 0 to 1099\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1100 non-null   int64  \n",
      " 1   MSSubClass     1100 non-null   int64  \n",
      " 2   MSZoning       1100 non-null   object \n",
      " 3   LotFrontage    908 non-null    float64\n",
      " 4   LotArea        1100 non-null   int64  \n",
      " 5   Street         1100 non-null   object \n",
      " 6   Alley          69 non-null     object \n",
      " 7   LotShape       1100 non-null   object \n",
      " 8   LandContour    1100 non-null   object \n",
      " 9   Utilities      1100 non-null   object \n",
      " 10  LotConfig      1100 non-null   object \n",
      " 11  LandSlope      1100 non-null   object \n",
      " 12  Neighborhood   1100 non-null   object \n",
      " 13  Condition1     1100 non-null   object \n",
      " 14  Condition2     1100 non-null   object \n",
      " 15  BldgType       1100 non-null   object \n",
      " 16  HouseStyle     1100 non-null   object \n",
      " 17  OverallQual    1100 non-null   int64  \n",
      " 18  OverallCond    1100 non-null   int64  \n",
      " 19  YearBuilt      1100 non-null   int64  \n",
      " 20  YearRemodAdd   1100 non-null   int64  \n",
      " 21  RoofStyle      1100 non-null   object \n",
      " 22  RoofMatl       1100 non-null   object \n",
      " 23  Exterior1st    1100 non-null   object \n",
      " 24  Exterior2nd    1100 non-null   object \n",
      " 25  MasVnrType     1094 non-null   object \n",
      " 26  MasVnrArea     1094 non-null   float64\n",
      " 27  ExterQual      1100 non-null   object \n",
      " 28  ExterCond      1100 non-null   object \n",
      " 29  Foundation     1100 non-null   object \n",
      " 30  BsmtQual       1069 non-null   object \n",
      " 31  BsmtCond       1069 non-null   object \n",
      " 32  BsmtExposure   1068 non-null   object \n",
      " 33  BsmtFinType1   1069 non-null   object \n",
      " 34  BsmtFinSF1     1100 non-null   int64  \n",
      " 35  BsmtFinType2   1068 non-null   object \n",
      " 36  BsmtFinSF2     1100 non-null   int64  \n",
      " 37  BsmtUnfSF      1100 non-null   int64  \n",
      " 38  TotalBsmtSF    1100 non-null   int64  \n",
      " 39  Heating        1100 non-null   object \n",
      " 40  HeatingQC      1100 non-null   object \n",
      " 41  CentralAir     1100 non-null   object \n",
      " 42  Electrical     1100 non-null   object \n",
      " 43  1stFlrSF       1100 non-null   int64  \n",
      " 44  2ndFlrSF       1100 non-null   int64  \n",
      " 45  LowQualFinSF   1100 non-null   int64  \n",
      " 46  GrLivArea      1100 non-null   int64  \n",
      " 47  BsmtFullBath   1100 non-null   int64  \n",
      " 48  BsmtHalfBath   1100 non-null   int64  \n",
      " 49  FullBath       1100 non-null   int64  \n",
      " 50  HalfBath       1100 non-null   int64  \n",
      " 51  BedroomAbvGr   1100 non-null   int64  \n",
      " 52  KitchenAbvGr   1100 non-null   int64  \n",
      " 53  KitchenQual    1100 non-null   object \n",
      " 54  TotRmsAbvGrd   1100 non-null   int64  \n",
      " 55  Functional     1100 non-null   object \n",
      " 56  Fireplaces     1100 non-null   int64  \n",
      " 57  FireplaceQu    576 non-null    object \n",
      " 58  GarageType     1039 non-null   object \n",
      " 59  GarageYrBlt    1039 non-null   float64\n",
      " 60  GarageFinish   1039 non-null   object \n",
      " 61  GarageCars     1100 non-null   int64  \n",
      " 62  GarageArea     1100 non-null   int64  \n",
      " 63  GarageQual     1039 non-null   object \n",
      " 64  GarageCond     1039 non-null   object \n",
      " 65  PavedDrive     1100 non-null   object \n",
      " 66  WoodDeckSF     1100 non-null   int64  \n",
      " 67  OpenPorchSF    1100 non-null   int64  \n",
      " 68  EnclosedPorch  1100 non-null   int64  \n",
      " 69  3SsnPorch      1100 non-null   int64  \n",
      " 70  ScreenPorch    1100 non-null   int64  \n",
      " 71  PoolArea       1100 non-null   int64  \n",
      " 72  PoolQC         2 non-null      object \n",
      " 73  Fence          208 non-null    object \n",
      " 74  MiscFeature    46 non-null     object \n",
      " 75  MiscVal        1100 non-null   int64  \n",
      " 76  MoSold         1100 non-null   int64  \n",
      " 77  YrSold         1100 non-null   int64  \n",
      " 78  SaleType       1100 non-null   object \n",
      " 79  SaleCondition  1100 non-null   object \n",
      " 80  SalePrice      1100 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 696.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Id','Alley','PoolQC','MiscFeature'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'Fence', 'SaleType', 'SaleCondition']\n",
      "['MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'Fence']\n",
      "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n"
     ]
    }
   ],
   "source": [
    "columns = data.columns\n",
    "data_types = data.dtypes\n",
    "col_counts = data.count()\n",
    "\n",
    "N = data.shape[0]\n",
    "\n",
    "obj_cols = []\n",
    "missing_obj_cols = []\n",
    "missing_num_cols = []\n",
    "\n",
    "for i in range(data.shape[1]):  \n",
    "    if data_types[i]=='object' and col_counts[i]!=N:\n",
    "        missing_obj_cols.append(columns[i])\n",
    "        \n",
    "for i in range(data.shape[1]):        \n",
    "    if data_types[i]=='object':\n",
    "        obj_cols.append(columns[i])\n",
    "        \n",
    "print(obj_cols)\n",
    "print(missing_obj_cols)\n",
    "\n",
    " \n",
    "for j in range(data.shape[1]):\n",
    "    if (data_types[j]=='int64' or data_types[j]=='float64') and col_counts[j]!=N:\n",
    "        missing_num_cols.append(columns[j])\n",
    "        \n",
    "print(missing_num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in missing_obj_cols:\n",
    "    data[i].fillna('NAN',inplace=True)\n",
    "    \n",
    "    \n",
    "\n",
    "for j in missing_num_cols:\n",
    "    data[j].fillna(data[j].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the data in numerical form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100 entries, 0 to 1099\n",
      "Data columns (total 77 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1100 non-null   int64  \n",
      " 1   MSZoning       1100 non-null   int32  \n",
      " 2   LotFrontage    1100 non-null   float64\n",
      " 3   LotArea        1100 non-null   int64  \n",
      " 4   Street         1100 non-null   int32  \n",
      " 5   LotShape       1100 non-null   int32  \n",
      " 6   LandContour    1100 non-null   int32  \n",
      " 7   Utilities      1100 non-null   int32  \n",
      " 8   LotConfig      1100 non-null   int32  \n",
      " 9   LandSlope      1100 non-null   int32  \n",
      " 10  Neighborhood   1100 non-null   int32  \n",
      " 11  Condition1     1100 non-null   int32  \n",
      " 12  Condition2     1100 non-null   int32  \n",
      " 13  BldgType       1100 non-null   int32  \n",
      " 14  HouseStyle     1100 non-null   int32  \n",
      " 15  OverallQual    1100 non-null   int64  \n",
      " 16  OverallCond    1100 non-null   int64  \n",
      " 17  YearBuilt      1100 non-null   int64  \n",
      " 18  YearRemodAdd   1100 non-null   int64  \n",
      " 19  RoofStyle      1100 non-null   int32  \n",
      " 20  RoofMatl       1100 non-null   int32  \n",
      " 21  Exterior1st    1100 non-null   int32  \n",
      " 22  Exterior2nd    1100 non-null   int32  \n",
      " 23  MasVnrType     1100 non-null   int32  \n",
      " 24  MasVnrArea     1100 non-null   float64\n",
      " 25  ExterQual      1100 non-null   int32  \n",
      " 26  ExterCond      1100 non-null   int32  \n",
      " 27  Foundation     1100 non-null   int32  \n",
      " 28  BsmtQual       1100 non-null   int32  \n",
      " 29  BsmtCond       1100 non-null   int32  \n",
      " 30  BsmtExposure   1100 non-null   int32  \n",
      " 31  BsmtFinType1   1100 non-null   int32  \n",
      " 32  BsmtFinSF1     1100 non-null   int64  \n",
      " 33  BsmtFinType2   1100 non-null   int32  \n",
      " 34  BsmtFinSF2     1100 non-null   int64  \n",
      " 35  BsmtUnfSF      1100 non-null   int64  \n",
      " 36  TotalBsmtSF    1100 non-null   int64  \n",
      " 37  Heating        1100 non-null   int32  \n",
      " 38  HeatingQC      1100 non-null   int32  \n",
      " 39  CentralAir     1100 non-null   int32  \n",
      " 40  Electrical     1100 non-null   int32  \n",
      " 41  1stFlrSF       1100 non-null   int64  \n",
      " 42  2ndFlrSF       1100 non-null   int64  \n",
      " 43  LowQualFinSF   1100 non-null   int64  \n",
      " 44  GrLivArea      1100 non-null   int64  \n",
      " 45  BsmtFullBath   1100 non-null   int64  \n",
      " 46  BsmtHalfBath   1100 non-null   int64  \n",
      " 47  FullBath       1100 non-null   int64  \n",
      " 48  HalfBath       1100 non-null   int64  \n",
      " 49  BedroomAbvGr   1100 non-null   int64  \n",
      " 50  KitchenAbvGr   1100 non-null   int64  \n",
      " 51  KitchenQual    1100 non-null   int32  \n",
      " 52  TotRmsAbvGrd   1100 non-null   int64  \n",
      " 53  Functional     1100 non-null   int32  \n",
      " 54  Fireplaces     1100 non-null   int64  \n",
      " 55  FireplaceQu    1100 non-null   int32  \n",
      " 56  GarageType     1100 non-null   int32  \n",
      " 57  GarageYrBlt    1100 non-null   float64\n",
      " 58  GarageFinish   1100 non-null   int32  \n",
      " 59  GarageCars     1100 non-null   int64  \n",
      " 60  GarageArea     1100 non-null   int64  \n",
      " 61  GarageQual     1100 non-null   int32  \n",
      " 62  GarageCond     1100 non-null   int32  \n",
      " 63  PavedDrive     1100 non-null   int32  \n",
      " 64  WoodDeckSF     1100 non-null   int64  \n",
      " 65  OpenPorchSF    1100 non-null   int64  \n",
      " 66  EnclosedPorch  1100 non-null   int64  \n",
      " 67  3SsnPorch      1100 non-null   int64  \n",
      " 68  ScreenPorch    1100 non-null   int64  \n",
      " 69  PoolArea       1100 non-null   int64  \n",
      " 70  Fence          1100 non-null   int32  \n",
      " 71  MiscVal        1100 non-null   int64  \n",
      " 72  MoSold         1100 non-null   int64  \n",
      " 73  YrSold         1100 non-null   int64  \n",
      " 74  SaleType       1100 non-null   int32  \n",
      " 75  SaleCondition  1100 non-null   int32  \n",
      " 76  SalePrice      1100 non-null   int64  \n",
      "dtypes: float64(3), int32(40), int64(34)\n",
      "memory usage: 490.0 KB\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "cv = CountVectorizer()\n",
    "\n",
    "    \n",
    "for i in obj_cols:\n",
    "    data[i] = le.fit_transform(data[i])\n",
    "\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  LandContour  \\\n",
       "0          60         3         65.0     8450       1         3            3   \n",
       "1          20         3         80.0     9600       1         3            3   \n",
       "2          60         3         68.0    11250       1         0            3   \n",
       "3          70         3         60.0     9550       1         0            3   \n",
       "4          60         3         84.0    14260       1         0            3   \n",
       "\n",
       "   Utilities  LotConfig  LandSlope  ...  3SsnPorch  ScreenPorch  PoolArea  \\\n",
       "0          0          4          0  ...          0            0         0   \n",
       "1          0          2          0  ...          0            0         0   \n",
       "2          0          4          0  ...          0            0         0   \n",
       "3          0          0          0  ...          0            0         0   \n",
       "4          0          2          0  ...          0            0         0   \n",
       "\n",
       "   Fence  MiscVal  MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      4        0       2    2008         8              4     208500  \n",
       "1      4        0       5    2007         8              4     181500  \n",
       "2      4        0       9    2008         8              4     223500  \n",
       "3      4        0       2    2006         8              0     140000  \n",
       "4      4        0      12    2008         8              4     250000  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating X and Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 76)\n",
      "(1100,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('SalePrice',axis=1)\n",
    "Y = data['SalePrice']\n",
    "\n",
    "X_train = X.values\n",
    "Y_train = Y.values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "n = X_train.shape\n",
    "\n",
    "model.add(Dense(20,activation = 'relu',input_shape = (X_train.shape[1],))) \n",
    "model.add(Dense(12,activation = 'relu'))\n",
    "model.add(Dense(10,activation = 'relu'))\n",
    "model.add(Dense(8,activation = 'relu'))\n",
    "model.add(Dense(4,activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 20)                1540      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12)                252       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 2,051\n",
      "Trainable params: 2,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the data in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 39018745856.0000 - val_loss: 39464054784.0000\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 39018676224.0000 - val_loss: 39463989248.0000\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39018598400.0000 - val_loss: 39463882752.0000\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39018459136.0000 - val_loss: 39463694336.0000\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39018221568.0000 - val_loss: 39463366656.0000\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39017795584.0000 - val_loss: 39462817792.0000\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - ETA: 0s - loss: 37591187456.000 - 0s 3ms/step - loss: 39017103360.0000 - val_loss: 39461896192.0000\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39015952384.0000 - val_loss: 39460352000.0000\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39014043648.0000 - val_loss: 39457837056.0000\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39010926592.0000 - val_loss: 39453974528.0000\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 39006314496.0000 - val_loss: 39448178688.0000\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38999293952.0000 - val_loss: 39439355904.0000\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38988988416.0000 - val_loss: 39426850816.0000\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38975221760.0000 - val_loss: 39410556928.0000\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38956380160.0000 - val_loss: 39387832320.0000\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38930440192.0000 - val_loss: 39357591552.0000\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38896832512.0000 - val_loss: 39319003136.0000\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38855065600.0000 - val_loss: 39270522880.0000\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38800109568.0000 - val_loss: 39205707776.0000\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38726336512.0000 - val_loss: 39121993728.0000\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38638317568.0000 - val_loss: 39022198784.0000\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38527115264.0000 - val_loss: 38894653440.0000\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38387269632.0000 - val_loss: 38737334272.0000\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38215983104.0000 - val_loss: 38545379328.0000\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 38016118784.0000 - val_loss: 38322614272.0000\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37772562432.0000 - val_loss: 38052831232.0000\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37477928960.0000 - val_loss: 37725933568.0000\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 37143027712.0000 - val_loss: 37354475520.0000\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 36733706240.0000 - val_loss: 36895547392.0000\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 36251836416.0000 - val_loss: 36382310400.0000\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 35698995200.0000 - val_loss: 35772420096.0000\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 35063615488.0000 - val_loss: 35075534848.0000\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 34313771008.0000 - val_loss: 34273236992.0000\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 33497393152.0000 - val_loss: 33408475136.0000\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 32599779328.0000 - val_loss: 32421756928.0000\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 31556732928.0000 - val_loss: 31312443392.0000\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 30408646656.0000 - val_loss: 30083186688.0000\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 29120049152.0000 - val_loss: 28721285120.0000\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 27740375040.0000 - val_loss: 27248764928.0000\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 26162132992.0000 - val_loss: 25573924864.0000\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 24496365568.0000 - val_loss: 23837093888.0000\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 22712905728.0000 - val_loss: 21995216896.0000\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 20847734784.0000 - val_loss: 20073897984.0000\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 18889730048.0000 - val_loss: 18060075008.0000\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 16911942656.0000 - val_loss: 16064802816.0000\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14971374592.0000 - val_loss: 14157194240.0000\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 13067863040.0000 - val_loss: 12240375808.0000\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 11209091072.0000 - val_loss: 10468736000.0000\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 9566141440.0000 - val_loss: 9004853248.0000\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 8189050368.0000 - val_loss: 7744414720.0000\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 7088278528.0000 - val_loss: 6839859712.0000\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 6346434560.0000 - val_loss: 6312305152.0000\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 5921719808.0000 - val_loss: 6051296256.0000\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 5703969792.0000 - val_loss: 5916888064.0000\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 5550422016.0000 - val_loss: 5801941504.0000\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 5407224832.0000 - val_loss: 5694229504.0000\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 5280998400.0000 - val_loss: 5583050752.0000\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 5146356224.0000 - val_loss: 5474630144.0000\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 5015475200.0000 - val_loss: 5373647872.0000\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4887673856.0000 - val_loss: 5272420864.0000\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4769183744.0000 - val_loss: 5176141312.0000\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4649315328.0000 - val_loss: 5062684672.0000\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4524355072.0000 - val_loss: 4966672384.0000\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4413498880.0000 - val_loss: 4862102528.0000\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4298295296.0000 - val_loss: 4763132928.0000\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 4193161728.0000 - val_loss: 4673359360.0000\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 4091360000.0000 - val_loss: 4575680000.0000\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3986869760.0000 - val_loss: 4480452608.0000\n",
      "Epoch 69/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 3891335168.0000 - val_loss: 4385766912.0000\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3800492288.0000 - val_loss: 4298338304.0000\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3700347904.0000 - val_loss: 4215296512.0000\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3608454912.0000 - val_loss: 4131659520.0000\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3525297152.0000 - val_loss: 4044187136.0000\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3437187072.0000 - val_loss: 3962468096.0000\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3356009728.0000 - val_loss: 3880034048.0000\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3280878592.0000 - val_loss: 3806101760.0000\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3206081792.0000 - val_loss: 3735684096.0000\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3142724864.0000 - val_loss: 3662687744.0000\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3066375936.0000 - val_loss: 3593862400.0000\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 3005587968.0000 - val_loss: 3531675648.0000\n",
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2943170048.0000 - val_loss: 3469804800.0000\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2886653952.0000 - val_loss: 3406571776.0000\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2829645312.0000 - val_loss: 3348106496.0000\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2773117184.0000 - val_loss: 3288526080.0000\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2724224256.0000 - val_loss: 3232576000.0000\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2674131200.0000 - val_loss: 3182889984.0000\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2627696384.0000 - val_loss: 3132215808.0000\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2584574720.0000 - val_loss: 3084324096.0000\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2546812416.0000 - val_loss: 3039592704.0000\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2507678464.0000 - val_loss: 2991046400.0000\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2465737728.0000 - val_loss: 2946351360.0000\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2426272512.0000 - val_loss: 2906564096.0000\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2391099648.0000 - val_loss: 2865163264.0000\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2351783168.0000 - val_loss: 2825848064.0000\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2326574336.0000 - val_loss: 2787265792.0000\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2292626688.0000 - val_loss: 2752381696.0000\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2264537088.0000 - val_loss: 2717758208.0000\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2235057152.0000 - val_loss: 2687618816.0000\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2207024128.0000 - val_loss: 2656590336.0000\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2176520704.0000 - val_loss: 2625157632.0000\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2152029696.0000 - val_loss: 2597895936.0000\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2130967296.0000 - val_loss: 2565545216.0000\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2101172352.0000 - val_loss: 2537666048.0000\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2075934848.0000 - val_loss: 2510093568.0000\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 2054402432.0000 - val_loss: 2482048512.0000\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2030696192.0000 - val_loss: 2455735552.0000\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 2009758848.0000 - val_loss: 2429779456.0000\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1989181952.0000 - val_loss: 2408300800.0000\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1966020480.0000 - val_loss: 2386514176.0000\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1947900160.0000 - val_loss: 2363362560.0000\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1930566016.0000 - val_loss: 2341503488.0000\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1912666240.0000 - val_loss: 2320740864.0000\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1893486336.0000 - val_loss: 2299589376.0000\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1874611456.0000 - val_loss: 2279782656.0000\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1857798016.0000 - val_loss: 2262734336.0000\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1838077312.0000 - val_loss: 2244344832.0000\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1823433728.0000 - val_loss: 2224367616.0000\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1806821760.0000 - val_loss: 2205859840.0000\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1787373440.0000 - val_loss: 2187248384.0000\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1772600064.0000 - val_loss: 2169369344.0000\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1758473216.0000 - val_loss: 2154036480.0000\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1747021824.0000 - val_loss: 2133651328.0000\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1729576448.0000 - val_loss: 2117366272.0000\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1718198656.0000 - val_loss: 2101417472.0000\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1692736512.0000 - val_loss: 2091380352.0000\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1684438656.0000 - val_loss: 2070831232.0000\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1668543360.0000 - val_loss: 2055365376.0000\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1661019648.0000 - val_loss: 2042002432.0000\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1645746816.0000 - val_loss: 2026329984.0000\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1631762688.0000 - val_loss: 2011722112.0000\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1615529600.0000 - val_loss: 1996862080.0000\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1606306816.0000 - val_loss: 1983424384.0000\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1587465472.0000 - val_loss: 1973614080.0000\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1582543232.0000 - val_loss: 1958134528.0000\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1566477184.0000 - val_loss: 1945856512.0000\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1550027008.0000 - val_loss: 1934834560.0000\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1543906688.0000 - val_loss: 1919698048.0000\n",
      "Epoch 138/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 1532809856.0000 - val_loss: 1906939776.0000\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1513702528.0000 - val_loss: 1897887232.0000\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1506066560.0000 - val_loss: 1886245888.0000\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1491441024.0000 - val_loss: 1872368256.0000\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1480583040.0000 - val_loss: 1864131840.0000\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1476023424.0000 - val_loss: 1844798080.0000\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1457405056.0000 - val_loss: 1834679936.0000\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1446902016.0000 - val_loss: 1823463808.0000\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1435363200.0000 - val_loss: 1808840320.0000\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1431770368.0000 - val_loss: 1798216064.0000\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1413848064.0000 - val_loss: 1790003968.0000\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1406757888.0000 - val_loss: 1774349824.0000\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1397556352.0000 - val_loss: 1763465728.0000\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1386036224.0000 - val_loss: 1753484544.0000\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1377765248.0000 - val_loss: 1743540736.0000\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1368345216.0000 - val_loss: 1734799744.0000\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1363004928.0000 - val_loss: 1723047808.0000\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1346802944.0000 - val_loss: 1714388224.0000\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1346643968.0000 - val_loss: 1703215744.0000\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1329219072.0000 - val_loss: 1694152448.0000\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1324080512.0000 - val_loss: 1686663680.0000\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1321394816.0000 - val_loss: 1675745408.0000\n",
      "Epoch 160/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1303603968.0000 - val_loss: 1668347008.0000\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1303557120.0000 - val_loss: 1656307584.0000\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1291617920.0000 - val_loss: 1646172928.0000\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1280705280.0000 - val_loss: 1638780416.0000\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1271187456.0000 - val_loss: 1633591168.0000\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1263456512.0000 - val_loss: 1624714880.0000\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1255137280.0000 - val_loss: 1613319424.0000\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1249691392.0000 - val_loss: 1609814784.0000\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1241265280.0000 - val_loss: 1596700416.0000\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1229202048.0000 - val_loss: 1591021440.0000\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1232274048.0000 - val_loss: 1579883008.0000\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1217665280.0000 - val_loss: 1574960768.0000\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1213458432.0000 - val_loss: 1563406976.0000\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1206573184.0000 - val_loss: 1555817216.0000\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1199024384.0000 - val_loss: 1548806272.0000\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1187468416.0000 - val_loss: 1550658304.0000\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1184290560.0000 - val_loss: 1531699328.0000\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1177263488.0000 - val_loss: 1522424320.0000\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1175229312.0000 - val_loss: 1514451968.0000\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1165729408.0000 - val_loss: 1506274048.0000\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1154997760.0000 - val_loss: 1500907264.0000\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1151979904.0000 - val_loss: 1489744256.0000\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1144426624.0000 - val_loss: 1483405696.0000\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 1138922368.0000 - val_loss: 1476768256.0000\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1131301248.0000 - val_loss: 1468837248.0000\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1132470528.0000 - val_loss: 1462222080.0000\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1115588352.0000 - val_loss: 1455082752.0000\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1118271232.0000 - val_loss: 1447309952.0000\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1103999360.0000 - val_loss: 1440897152.0000\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1099081216.0000 - val_loss: 1434294016.0000\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1097030272.0000 - val_loss: 1425711104.0000\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1089981440.0000 - val_loss: 1420134784.0000\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1086218624.0000 - val_loss: 1414396672.0000\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1079703552.0000 - val_loss: 1410545280.0000\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1073605056.0000 - val_loss: 1399101952.0000\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1066810176.0000 - val_loss: 1393069056.0000\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1066086208.0000 - val_loss: 1388877952.0000\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1056574400.0000 - val_loss: 1381215488.0000\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1052700480.0000 - val_loss: 1374263168.0000\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1045837824.0000 - val_loss: 1372426752.0000\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1045745792.0000 - val_loss: 1366507904.0000\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1036107008.0000 - val_loss: 1361198336.0000\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1035310976.0000 - val_loss: 1349751296.0000\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1030846720.0000 - val_loss: 1342192000.0000\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1021300928.0000 - val_loss: 1336905728.0000\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1021145792.0000 - val_loss: 1329805184.0000\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1013892864.0000 - val_loss: 1323949696.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1003880064.0000 - val_loss: 1322351872.0000\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1006626496.0000 - val_loss: 1310104448.0000\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 991202304.0000 - val_loss: 1315971840.0000\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 997187072.0000 - val_loss: 1299546240.0000\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 986855040.0000 - val_loss: 1293302528.0000\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 988179968.0000 - val_loss: 1288301824.0000\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 980463296.0000 - val_loss: 1283754752.0000\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 975928768.0000 - val_loss: 1279058944.0000\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 973116992.0000 - val_loss: 1273634176.0000\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 966170368.0000 - val_loss: 1268965376.0000\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 960153408.0000 - val_loss: 1261354624.0000\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 952972928.0000 - val_loss: 1254826112.0000\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 954735488.0000 - val_loss: 1250478720.0000\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 950417024.0000 - val_loss: 1245425536.0000\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 945735680.0000 - val_loss: 1239581696.0000\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 939548608.0000 - val_loss: 1234061184.0000\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 936913920.0000 - val_loss: 1229811072.0000\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 931196736.0000 - val_loss: 1228528640.0000\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 928747904.0000 - val_loss: 1228717184.0000\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 926122176.0000 - val_loss: 1220038016.0000\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 918602944.0000 - val_loss: 1223721856.0000\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 916431744.0000 - val_loss: 1213135232.0000\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 914614976.0000 - val_loss: 1211028992.0000\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 907036096.0000 - val_loss: 1207751168.0000\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 906733184.0000 - val_loss: 1196063744.0000\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 900976640.0000 - val_loss: 1196383232.0000\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 899152128.0000 - val_loss: 1189482880.0000\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 893177856.0000 - val_loss: 1188068864.0000\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 894820864.0000 - val_loss: 1179873280.0000\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 888408192.0000 - val_loss: 1175668096.0000\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 881739584.0000 - val_loss: 1179513856.0000\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 881964032.0000 - val_loss: 1177014784.0000\n",
      "Epoch 239/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 875378368.0000 - val_loss: 1169413760.0000\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 872789376.0000 - val_loss: 1165250304.0000\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 871781760.0000 - val_loss: 1158673408.0000\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 869495680.0000 - val_loss: 1156955648.0000\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 866694976.0000 - val_loss: 1150624512.0000\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 860711744.0000 - val_loss: 1146285952.0000\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 861378240.0000 - val_loss: 1144985216.0000\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 851910720.0000 - val_loss: 1138006144.0000\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 854218688.0000 - val_loss: 1133945856.0000\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 848127424.0000 - val_loss: 1131563520.0000\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 846985984.0000 - val_loss: 1128313600.0000\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 842937920.0000 - val_loss: 1130792576.0000\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 840550208.0000 - val_loss: 1121579776.0000\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 841912448.0000 - val_loss: 1122268672.0000\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 829450112.0000 - val_loss: 1115359104.0000\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 829222592.0000 - val_loss: 1121682048.0000\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 830452608.0000 - val_loss: 1110853120.0000\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 825028672.0000 - val_loss: 1109550080.0000\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 826567296.0000 - val_loss: 1107957888.0000\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 823536448.0000 - val_loss: 1104574848.0000\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 819008384.0000 - val_loss: 1105714432.0000\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 813504576.0000 - val_loss: 1101671040.0000\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 814758080.0000 - val_loss: 1098870784.0000\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 809328512.0000 - val_loss: 1098352512.0000\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 805061440.0000 - val_loss: 1090791040.0000\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 803401792.0000 - val_loss: 1092468864.0000\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 802199680.0000 - val_loss: 1087475584.0000\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 797437824.0000 - val_loss: 1087226752.0000\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 794447552.0000 - val_loss: 1087587456.0000\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 789414720.0000 - val_loss: 1093649024.0000\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 789815744.0000 - val_loss: 1082234624.0000\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 784182784.0000 - val_loss: 1074197120.0000\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 780359040.0000 - val_loss: 1079165056.0000\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 781382784.0000 - val_loss: 1076383360.0000\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 784936256.0000 - val_loss: 1084347136.0000\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 771949440.0000 - val_loss: 1073885312.0000\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 773049472.0000 - val_loss: 1067314624.0000\n",
      "Epoch 276/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 771746816.0000 - val_loss: 1070625664.0000\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 766113792.0000 - val_loss: 1063346432.0000\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 761425920.0000 - val_loss: 1067892800.0000\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 763530880.0000 - val_loss: 1069199552.0000\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 756664704.0000 - val_loss: 1054203072.0000\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 759324352.0000 - val_loss: 1052487936.0000\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 754744576.0000 - val_loss: 1048391744.0000\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 750241344.0000 - val_loss: 1054068992.0000\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 751552448.0000 - val_loss: 1054580736.0000\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 745326208.0000 - val_loss: 1048458432.0000\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 746299328.0000 - val_loss: 1045734464.0000\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 740905600.0000 - val_loss: 1050026496.0000\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 740794624.0000 - val_loss: 1048619392.0000\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 731918720.0000 - val_loss: 1035590848.0000\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 734475648.0000 - val_loss: 1036626880.0000\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 733073664.0000 - val_loss: 1042849280.0000\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 728512832.0000 - val_loss: 1040086400.0000\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 729706560.0000 - val_loss: 1038023552.0000\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 723740096.0000 - val_loss: 1031129984.0000\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 723788928.0000 - val_loss: 1031332416.0000\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 724928000.0000 - val_loss: 1035315200.0000\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 722166848.0000 - val_loss: 1031884608.0000\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 716325952.0000 - val_loss: 1032354624.0000\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 720175936.0000 - val_loss: 1033459456.0000\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 712526784.0000 - val_loss: 1031621440.0000\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 711290304.0000 - val_loss: 1034912128.0000\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 708418752.0000 - val_loss: 1019484544.0000\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 711709504.0000 - val_loss: 1022896640.0000\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 707132928.0000 - val_loss: 1020361664.0000\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 703176960.0000 - val_loss: 1028341696.0000\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 703604928.0000 - val_loss: 1021075136.0000\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 700830784.0000 - val_loss: 1015513344.0000\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 697908224.0000 - val_loss: 1015662912.0000\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 696335232.0000 - val_loss: 1016292736.0000\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 692377664.0000 - val_loss: 1028008192.0000\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 686814016.0000 - val_loss: 1008484032.0000\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 690324224.0000 - val_loss: 1022476800.0000\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 691726528.0000 - val_loss: 1013610304.0000\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 686979776.0000 - val_loss: 1011322048.0000\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 685862720.0000 - val_loss: 1005289536.0000\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 682982080.0000 - val_loss: 1007330688.0000\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 681965440.0000 - val_loss: 1004561024.0000\n",
      "Epoch 318/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 679714624.0000 - val_loss: 1012332032.0000\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 676068608.0000 - val_loss: 1012329024.0000\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 674174976.0000 - val_loss: 1014351808.0000\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 673210624.0000 - val_loss: 1016930624.0000\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 673127872.0000 - val_loss: 1000947712.0000\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 672872256.0000 - val_loss: 1000803392.0000\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 668924992.0000 - val_loss: 1003535104.0000\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 669513792.0000 - val_loss: 997983616.0000\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 665696128.0000 - val_loss: 999002112.0000\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 666758336.0000 - val_loss: 1003776576.0000\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 663279296.0000 - val_loss: 994221824.0000\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 661449024.0000 - val_loss: 996236096.0000\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 660134976.0000 - val_loss: 993630464.0000\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 657196672.0000 - val_loss: 991594304.0000\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 657079488.0000 - val_loss: 994388800.0000\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 654075072.0000 - val_loss: 1005471552.0000\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 655809408.0000 - val_loss: 993210560.0000\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 647969216.0000 - val_loss: 1003232960.0000\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 650468672.0000 - val_loss: 985714304.0000\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 646635456.0000 - val_loss: 994314432.0000\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 643817216.0000 - val_loss: 985804544.0000\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 649910272.0000 - val_loss: 983703168.0000\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 641426688.0000 - val_loss: 988708480.0000\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 639934400.0000 - val_loss: 998637184.0000\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 642331264.0000 - val_loss: 989657152.0000\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 639823936.0000 - val_loss: 992797504.0000\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 637863296.0000 - val_loss: 974735680.0000\n",
      "Epoch 345/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 635393472.0000 - val_loss: 978670784.0000\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 633228160.0000 - val_loss: 982550144.0000\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 633019840.0000 - val_loss: 973920192.0000\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 628850624.0000 - val_loss: 970912128.0000\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 630302464.0000 - val_loss: 971238144.0000\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 625006272.0000 - val_loss: 966463872.0000\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 625806016.0000 - val_loss: 968276160.0000\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 623245312.0000 - val_loss: 980358016.0000\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 623626176.0000 - val_loss: 979249728.0000\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 619181760.0000 - val_loss: 979431616.0000\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 617758528.0000 - val_loss: 976074112.0000\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 618453184.0000 - val_loss: 977697920.0000\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 617076736.0000 - val_loss: 964611520.0000\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 615397952.0000 - val_loss: 958398272.0000\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 612552384.0000 - val_loss: 956694016.0000\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 610904000.0000 - val_loss: 978511936.0000\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 609810496.0000 - val_loss: 955800704.0000\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 608534848.0000 - val_loss: 957322176.0000\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 605002816.0000 - val_loss: 975756672.0000\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 610557696.0000 - val_loss: 972158720.0000\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 604458368.0000 - val_loss: 970199680.0000\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 600724992.0000 - val_loss: 959395200.0000\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 606630784.0000 - val_loss: 961544512.0000\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 599626176.0000 - val_loss: 965644608.0000\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 595933440.0000 - val_loss: 947764480.0000\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 597904128.0000 - val_loss: 955013760.0000\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 595872704.0000 - val_loss: 948839808.0000\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 592934016.0000 - val_loss: 961081088.0000\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 592971392.0000 - val_loss: 949424128.0000\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 590464768.0000 - val_loss: 950311168.0000\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 585492096.0000 - val_loss: 978208832.0000\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 590039360.0000 - val_loss: 965687872.0000\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 588254528.0000 - val_loss: 947950848.0000\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 586956608.0000 - val_loss: 955387328.0000\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 582445504.0000 - val_loss: 966808960.0000\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 584901568.0000 - val_loss: 954247232.0000\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 580471040.0000 - val_loss: 948199168.0000\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 583370368.0000 - val_loss: 947465984.0000\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 580000064.0000 - val_loss: 946331712.0000\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 575052096.0000 - val_loss: 941111680.0000\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 576075008.0000 - val_loss: 942923584.0000\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 572439040.0000 - val_loss: 940926976.0000\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 575798528.0000 - val_loss: 941221632.0000\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 570823168.0000 - val_loss: 958153856.0000\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 572217920.0000 - val_loss: 944885440.0000\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 568392960.0000 - val_loss: 957748096.0000\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 571512064.0000 - val_loss: 940521408.0000\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 566334336.0000 - val_loss: 943397824.0000\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 569048384.0000 - val_loss: 943803840.0000\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 564238976.0000 - val_loss: 939126848.0000\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 560943104.0000 - val_loss: 930201024.0000\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 563667584.0000 - val_loss: 941964480.0000\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 560313152.0000 - val_loss: 951476480.0000\n",
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 558638784.0000 - val_loss: 958798976.0000\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 561280960.0000 - val_loss: 942137408.0000\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 556186368.0000 - val_loss: 935396288.0000\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 555334528.0000 - val_loss: 938699264.0000\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 558534720.0000 - val_loss: 942660224.0000\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 551723648.0000 - val_loss: 927327680.0000\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 552069568.0000 - val_loss: 940581184.0000\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 548320960.0000 - val_loss: 953621440.0000\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 551948992.0000 - val_loss: 940611072.0000\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 549829376.0000 - val_loss: 926470912.0000\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 550414592.0000 - val_loss: 932563456.0000\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 548455424.0000 - val_loss: 933493056.0000\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 545993600.0000 - val_loss: 933189696.0000\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 545690496.0000 - val_loss: 935040512.0000\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 540022592.0000 - val_loss: 916004288.0000\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 540877632.0000 - val_loss: 938308416.0000\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 544086976.0000 - val_loss: 929800000.0000\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 538911424.0000 - val_loss: 933136320.0000\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 533715648.0000 - val_loss: 912937024.0000\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 542278592.0000 - val_loss: 921816128.0000\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 536908736.0000 - val_loss: 926723264.0000\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 532125120.0000 - val_loss: 962990592.0000\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 539071232.0000 - val_loss: 918479104.0000\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 530853856.0000 - val_loss: 935961472.0000\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 531958240.0000 - val_loss: 914382848.0000\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 529164448.0000 - val_loss: 934084608.0000\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 523493408.0000 - val_loss: 908003520.0000\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 534905472.0000 - val_loss: 920756160.0000\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 526312736.0000 - val_loss: 917499136.0000\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 529827424.0000 - val_loss: 917080832.0000\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 520065888.0000 - val_loss: 933034368.0000\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 523059584.0000 - val_loss: 923097024.0000\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 525093664.0000 - val_loss: 916992768.0000\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 524088736.0000 - val_loss: 922198080.0000\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 518139264.0000 - val_loss: 921924800.0000\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 516487200.0000 - val_loss: 906133120.0000\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 522831520.0000 - val_loss: 910373760.0000\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 522242336.0000 - val_loss: 923827392.0000\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 517432416.0000 - val_loss: 933269696.0000\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 518371648.0000 - val_loss: 917747392.0000\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 516248320.0000 - val_loss: 921480320.0000\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 512967680.0000 - val_loss: 906802688.0000\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 514588064.0000 - val_loss: 917189440.0000\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 511939392.0000 - val_loss: 927854656.0000\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 512052896.0000 - val_loss: 916863360.0000\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 508757568.0000 - val_loss: 929495936.0000\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 511592544.0000 - val_loss: 925223744.0000\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 511893216.0000 - val_loss: 931235776.0000\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 505318976.0000 - val_loss: 921817344.0000\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 506118336.0000 - val_loss: 939456768.0000\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 505300768.0000 - val_loss: 931317952.0000\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 504791168.0000 - val_loss: 911838912.0000\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 504394816.0000 - val_loss: 906754816.0000\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 505606112.0000 - val_loss: 911362560.0000\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 503758112.0000 - val_loss: 920872960.0000\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 500445568.0000 - val_loss: 921227776.0000\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 503697760.0000 - val_loss: 921062272.0000\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 498453952.0000 - val_loss: 913086656.0000\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 497830784.0000 - val_loss: 911854208.0000\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 496496416.0000 - val_loss: 915767936.0000\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 497153888.0000 - val_loss: 921045568.0000\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 496081120.0000 - val_loss: 931261568.0000\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 494046368.0000 - val_loss: 908910336.0000\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 495773280.0000 - val_loss: 923791680.0000\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 498567072.0000 - val_loss: 913838912.0000\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 490655200.0000 - val_loss: 934763904.0000\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 494864960.0000 - val_loss: 917240768.0000\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 490178560.0000 - val_loss: 922219008.0000\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 488499648.0000 - val_loss: 931393536.0000\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 491336544.0000 - val_loss: 911833600.0000\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 488440416.0000 - val_loss: 916252416.0000\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 489254080.0000 - val_loss: 910997120.0000\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 489639200.0000 - val_loss: 915117824.0000\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 485905664.0000 - val_loss: 916372032.0000\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 486079072.0000 - val_loss: 914878976.0000\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 486387968.0000 - val_loss: 903147584.0000\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 483621920.0000 - val_loss: 923183040.0000\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 481067648.0000 - val_loss: 931948160.0000\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 482805760.0000 - val_loss: 925606976.0000\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 478830112.0000 - val_loss: 938133824.0000\n",
      "Epoch 478/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 481969376.0000 - val_loss: 925895168.0000\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 473869760.0000 - val_loss: 892115264.0000\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 482386624.0000 - val_loss: 896628672.0000\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 476077280.0000 - val_loss: 914901824.0000\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 474426048.0000 - val_loss: 930700160.0000\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 480075136.0000 - val_loss: 917794176.0000\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 476234560.0000 - val_loss: 920892160.0000\n",
      "Epoch 485/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 474996352.0000 - val_loss: 915474688.0000\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 475409792.0000 - val_loss: 915943424.0000\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 471395968.0000 - val_loss: 917335744.0000\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 473127328.0000 - val_loss: 935664448.0000\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 472799040.0000 - val_loss: 901735872.0000\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 474103488.0000 - val_loss: 905312192.0000\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 467248896.0000 - val_loss: 930990272.0000\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 470505824.0000 - val_loss: 913032320.0000\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 468367392.0000 - val_loss: 907718272.0000\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 467202304.0000 - val_loss: 908783360.0000\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 469622496.0000 - val_loss: 921733312.0000\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 468893792.0000 - val_loss: 906615424.0000\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 464322944.0000 - val_loss: 909423104.0000\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 465491456.0000 - val_loss: 913285696.0000\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 464302400.0000 - val_loss: 917369600.0000\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 464468320.0000 - val_loss: 903897152.0000\n"
     ]
    }
   ],
   "source": [
    "x_val = X_train[:400]    #Splitting our data into training and validation\n",
    "y_val = Y[:400]\n",
    "\n",
    "\n",
    "x_train = X_train[400:]\n",
    "y_train = Y[400:]\n",
    "\n",
    "hist = model.fit(x_train,y_train,epochs=500,batch_size=32,validation_data = (x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising both training and validation loss and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['val_loss'],label=\"Validation loss\")\n",
    "plt.plot(hist.history['loss'],label = 'Training_loss')\n",
    "plt.title(\"Visualizing training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions on our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[250094.97 ],\n",
       "       [187397.36 ],\n",
       "       [106927.5  ],\n",
       "       [241732.73 ],\n",
       "       [170111.84 ],\n",
       "       [155859.08 ],\n",
       "       [108836.89 ],\n",
       "       [160013.31 ],\n",
       "       [301212.5  ],\n",
       "       [326052.22 ],\n",
       "       [ 79906.484],\n",
       "       [147463.14 ],\n",
       "       [273463.16 ],\n",
       "       [121205.19 ],\n",
       "       [226750.42 ],\n",
       "       [187173.67 ],\n",
       "       [151443.44 ],\n",
       "       [212396.81 ],\n",
       "       [125545.34 ],\n",
       "       [129691.36 ],\n",
       "       [210724.92 ],\n",
       "       [231658.19 ],\n",
       "       [119341.39 ],\n",
       "       [317003.75 ],\n",
       "       [126561.07 ],\n",
       "       [142224.61 ],\n",
       "       [281195.94 ],\n",
       "       [124910.16 ],\n",
       "       [203817.02 ],\n",
       "       [191543.03 ],\n",
       "       [ 89167.23 ],\n",
       "       [103750.41 ],\n",
       "       [107354.7  ],\n",
       "       [188592.58 ],\n",
       "       [ 92779.19 ],\n",
       "       [212783.89 ],\n",
       "       [ 99588.96 ],\n",
       "       [115138.7  ],\n",
       "       [ 76464.53 ],\n",
       "       [117166.75 ],\n",
       "       [515133.84 ],\n",
       "       [ 99437.39 ],\n",
       "       [159435.3  ],\n",
       "       [205293.55 ],\n",
       "       [196203.22 ],\n",
       "       [158743.75 ],\n",
       "       [202253.73 ],\n",
       "       [221220.36 ],\n",
       "       [132248.34 ],\n",
       "       [ 95016.56 ],\n",
       "       [132269.33 ],\n",
       "       [262559.12 ],\n",
       "       [207830.27 ],\n",
       "       [209301.08 ],\n",
       "       [189889.27 ],\n",
       "       [175617.38 ],\n",
       "       [ 77650.46 ],\n",
       "       [221142.89 ],\n",
       "       [160982.58 ],\n",
       "       [118582.16 ],\n",
       "       [233616.7  ],\n",
       "       [162501.48 ],\n",
       "       [ 84605.555],\n",
       "       [177102.66 ],\n",
       "       [124985.78 ],\n",
       "       [162522.34 ],\n",
       "       [147538.48 ],\n",
       "       [166566.19 ],\n",
       "       [247280.45 ],\n",
       "       [182209.06 ],\n",
       "       [216825.77 ],\n",
       "       [204367.9  ],\n",
       "       [145584.22 ],\n",
       "       [367830.   ],\n",
       "       [265030.44 ],\n",
       "       [122067.83 ],\n",
       "       [227963.56 ],\n",
       "       [407287.3  ],\n",
       "       [293219.84 ],\n",
       "       [ 95640.68 ],\n",
       "       [349868.12 ],\n",
       "       [340306.66 ],\n",
       "       [140349.52 ],\n",
       "       [171735.39 ],\n",
       "       [132442.67 ],\n",
       "       [120620.31 ],\n",
       "       [162351.1  ],\n",
       "       [203049.48 ],\n",
       "       [130755.17 ],\n",
       "       [ 93498.61 ],\n",
       "       [116310.19 ],\n",
       "       [137997.55 ],\n",
       "       [178026.77 ],\n",
       "       [152344.03 ],\n",
       "       [ 96785.57 ],\n",
       "       [ 75555.8  ],\n",
       "       [431925.06 ],\n",
       "       [163961.75 ],\n",
       "       [122836.11 ],\n",
       "       [119718.94 ],\n",
       "       [106112.18 ],\n",
       "       [211613.48 ],\n",
       "       [123616.51 ],\n",
       "       [277187.75 ],\n",
       "       [124198.53 ],\n",
       "       [116273.53 ],\n",
       "       [229425.72 ],\n",
       "       [177934.31 ],\n",
       "       [161997.73 ],\n",
       "       [141392.86 ],\n",
       "       [159929.72 ],\n",
       "       [203575.02 ],\n",
       "       [129024.92 ],\n",
       "       [133772.34 ],\n",
       "       [103068.42 ],\n",
       "       [397458.25 ],\n",
       "       [162627.16 ],\n",
       "       [287776.4  ],\n",
       "       [200555.36 ],\n",
       "       [242850.17 ],\n",
       "       [ 95175.56 ],\n",
       "       [155844.11 ],\n",
       "       [168252.16 ],\n",
       "       [410923.7  ],\n",
       "       [299067.4  ],\n",
       "       [181920.78 ],\n",
       "       [125287.56 ],\n",
       "       [415505.1  ],\n",
       "       [ 89240.58 ],\n",
       "       [194204.48 ],\n",
       "       [179022.67 ],\n",
       "       [142091.33 ],\n",
       "       [105103.95 ],\n",
       "       [ 45728.945],\n",
       "       [196468.61 ],\n",
       "       [ 97900.   ],\n",
       "       [200484.52 ],\n",
       "       [108577.61 ],\n",
       "       [131536.58 ],\n",
       "       [269640.28 ],\n",
       "       [397571.94 ],\n",
       "       [277526.94 ],\n",
       "       [218202.75 ],\n",
       "       [154928.58 ],\n",
       "       [192186.73 ],\n",
       "       [242997.02 ],\n",
       "       [188858.44 ],\n",
       "       [121796.95 ],\n",
       "       [132511.03 ],\n",
       "       [226408.28 ],\n",
       "       [131207.97 ],\n",
       "       [100636.5  ],\n",
       "       [279078.7  ],\n",
       "       [ 47258.902],\n",
       "       [270768.12 ],\n",
       "       [124472.7  ],\n",
       "       [105853.41 ],\n",
       "       [123387.47 ],\n",
       "       [182425.14 ],\n",
       "       [188256.11 ],\n",
       "       [166635.5  ],\n",
       "       [168147.   ],\n",
       "       [148149.77 ],\n",
       "       [162189.36 ],\n",
       "       [251159.55 ],\n",
       "       [120847.23 ],\n",
       "       [329368.5  ],\n",
       "       [193683.83 ],\n",
       "       [316570.34 ],\n",
       "       [118936.69 ],\n",
       "       [155235.14 ],\n",
       "       [116246.7  ],\n",
       "       [228473.36 ],\n",
       "       [172202.86 ],\n",
       "       [137015.66 ],\n",
       "       [ 90413.21 ],\n",
       "       [135015.64 ],\n",
       "       [155215.67 ],\n",
       "       [146015.39 ],\n",
       "       [ 92870.19 ],\n",
       "       [175859.5  ],\n",
       "       [344551.7  ],\n",
       "       [109949.016],\n",
       "       [320025.75 ],\n",
       "       [134658.92 ],\n",
       "       [379837.3  ],\n",
       "       [114925.82 ],\n",
       "       [117629.16 ],\n",
       "       [194559.58 ],\n",
       "       [103738.39 ],\n",
       "       [179724.72 ],\n",
       "       [426848.38 ],\n",
       "       [144795.45 ],\n",
       "       [145744.83 ],\n",
       "       [126667.08 ],\n",
       "       [338952.62 ],\n",
       "       [132135.1  ],\n",
       "       [203287.97 ],\n",
       "       [203792.55 ],\n",
       "       [148436.   ],\n",
       "       [275257.2  ],\n",
       "       [114991.164],\n",
       "       [232406.58 ],\n",
       "       [150484.62 ],\n",
       "       [218829.44 ],\n",
       "       [228421.02 ],\n",
       "       [143465.55 ],\n",
       "       [194158.52 ],\n",
       "       [316873.25 ],\n",
       "       [113823.2  ],\n",
       "       [326168.7  ],\n",
       "       [161335.11 ],\n",
       "       [253139.42 ],\n",
       "       [127333.81 ],\n",
       "       [ 85228.   ],\n",
       "       [130831.336],\n",
       "       [173522.23 ],\n",
       "       [112101.26 ],\n",
       "       [339366.06 ],\n",
       "       [336248.94 ],\n",
       "       [ 76686.44 ],\n",
       "       [261702.8  ],\n",
       "       [117131.14 ],\n",
       "       [180074.81 ],\n",
       "       [154178.22 ],\n",
       "       [170967.83 ],\n",
       "       [112996.67 ],\n",
       "       [161295.89 ],\n",
       "       [168036.23 ],\n",
       "       [163933.94 ],\n",
       "       [125451.41 ],\n",
       "       [228277.08 ],\n",
       "       [159030.8  ],\n",
       "       [151079.98 ],\n",
       "       [142348.58 ],\n",
       "       [203274.08 ],\n",
       "       [ 53233.844],\n",
       "       [ 91434.516],\n",
       "       [ 91848.2  ],\n",
       "       [278302.28 ],\n",
       "       [287858.84 ],\n",
       "       [235036.83 ],\n",
       "       [359149.06 ],\n",
       "       [149054.28 ],\n",
       "       [369346.62 ],\n",
       "       [124383.695],\n",
       "       [102306.516],\n",
       "       [158646.2  ],\n",
       "       [144854.67 ],\n",
       "       [101616.22 ],\n",
       "       [208235.14 ],\n",
       "       [117473.37 ],\n",
       "       [195666.92 ],\n",
       "       [152029.47 ],\n",
       "       [354979.   ],\n",
       "       [ 93938.96 ],\n",
       "       [136182.86 ],\n",
       "       [147250.12 ],\n",
       "       [106731.39 ],\n",
       "       [171567.5  ],\n",
       "       [219434.75 ],\n",
       "       [371180.7  ],\n",
       "       [116113.86 ],\n",
       "       [118153.58 ],\n",
       "       [397542.62 ],\n",
       "       [235217.3  ],\n",
       "       [133409.42 ],\n",
       "       [239222.55 ],\n",
       "       [177086.12 ],\n",
       "       [122544.016],\n",
       "       [166575.5  ],\n",
       "       [124833.39 ],\n",
       "       [150471.2  ],\n",
       "       [259987.36 ],\n",
       "       [150023.83 ],\n",
       "       [143087.5  ],\n",
       "       [101536.95 ],\n",
       "       [ 88276.16 ],\n",
       "       [352005.38 ],\n",
       "       [131874.56 ],\n",
       "       [121196.664],\n",
       "       [120848.43 ],\n",
       "       [176375.05 ],\n",
       "       [287264.1  ],\n",
       "       [203368.36 ],\n",
       "       [195801.36 ],\n",
       "       [250058.98 ],\n",
       "       [154649.02 ],\n",
       "       [272234.34 ],\n",
       "       [195429.55 ],\n",
       "       [138959.83 ],\n",
       "       [674418.25 ],\n",
       "       [319898.2  ],\n",
       "       [103210.164],\n",
       "       [134373.38 ],\n",
       "       [178938.22 ],\n",
       "       [128736.67 ],\n",
       "       [120053.82 ],\n",
       "       [144819.89 ],\n",
       "       [182012.39 ],\n",
       "       [335977.66 ],\n",
       "       [147684.27 ],\n",
       "       [366238.84 ],\n",
       "       [147356.73 ],\n",
       "       [206256.64 ],\n",
       "       [ 53175.094],\n",
       "       [319875.38 ],\n",
       "       [219477.97 ],\n",
       "       [182865.73 ],\n",
       "       [111460.4  ],\n",
       "       [ 65342.977],\n",
       "       [102121.08 ],\n",
       "       [173242.4  ],\n",
       "       [132456.5  ],\n",
       "       [176250.23 ],\n",
       "       [138697.39 ],\n",
       "       [170251.84 ],\n",
       "       [166368.36 ],\n",
       "       [310119.62 ],\n",
       "       [127129.164],\n",
       "       [259667.42 ],\n",
       "       [140979.81 ],\n",
       "       [120653.62 ],\n",
       "       [137070.38 ],\n",
       "       [326580.62 ],\n",
       "       [114436.92 ],\n",
       "       [215566.4  ],\n",
       "       [209158.47 ],\n",
       "       [123309.59 ],\n",
       "       [ 92984.19 ],\n",
       "       [241171.08 ],\n",
       "       [227287.36 ],\n",
       "       [227667.7  ],\n",
       "       [137412.   ],\n",
       "       [102593.484],\n",
       "       [156001.17 ],\n",
       "       [ 81528.695],\n",
       "       [226362.83 ],\n",
       "       [155076.38 ],\n",
       "       [193398.8  ],\n",
       "       [113694.586],\n",
       "       [143755.95 ],\n",
       "       [176945.84 ],\n",
       "       [162155.12 ],\n",
       "       [177469.44 ],\n",
       "       [312445.1  ],\n",
       "       [241182.92 ],\n",
       "       [257326.8  ],\n",
       "       [245032.45 ],\n",
       "       [111604.22 ],\n",
       "       [106320.34 ],\n",
       "       [148405.36 ],\n",
       "       [204161.11 ],\n",
       "       [287734.25 ],\n",
       "       [147872.61 ],\n",
       "       [173378.14 ],\n",
       "       [210417.23 ],\n",
       "       [138656.7  ],\n",
       "       [178586.58 ],\n",
       "       [289194.06 ],\n",
       "       [121479.54 ],\n",
       "       [ 93179.09 ],\n",
       "       [220758.02 ],\n",
       "       [337688.3  ],\n",
       "       [257278.38 ],\n",
       "       [268300.12 ],\n",
       "       [190085.11 ],\n",
       "       [176643.97 ],\n",
       "       [216437.52 ],\n",
       "       [520534.56 ],\n",
       "       [111656.91 ],\n",
       "       [108411.   ],\n",
       "       [121499.266],\n",
       "       [ 99064.42 ],\n",
       "       [317489.6  ],\n",
       "       [165794.53 ],\n",
       "       [229726.61 ],\n",
       "       [143579.19 ],\n",
       "       [141049.52 ],\n",
       "       [140675.1  ],\n",
       "       [167887.11 ],\n",
       "       [164420.7  ],\n",
       "       [173540.72 ],\n",
       "       [167292.36 ],\n",
       "       [120307.75 ],\n",
       "       [165389.72 ],\n",
       "       [138892.39 ],\n",
       "       [231484.98 ],\n",
       "       [101803.28 ],\n",
       "       [194769.83 ],\n",
       "       [146784.25 ],\n",
       "       [142388.62 ],\n",
       "       [245030.28 ],\n",
       "       [246232.55 ],\n",
       "       [207310.72 ],\n",
       "       [163246.17 ],\n",
       "       [132297.5  ],\n",
       "       [102911.08 ],\n",
       "       [487439.03 ],\n",
       "       [166458.78 ],\n",
       "       [192911.64 ],\n",
       "       [124982.56 ],\n",
       "       [193959.83 ],\n",
       "       [490315.25 ],\n",
       "       [118329.016],\n",
       "       [214823.44 ],\n",
       "       [127804.97 ],\n",
       "       [189878.83 ],\n",
       "       [149862.08 ],\n",
       "       [118768.35 ],\n",
       "       [181279.8  ],\n",
       "       [159352.25 ],\n",
       "       [ 54501.387],\n",
       "       [164600.86 ],\n",
       "       [103680.234],\n",
       "       [207090.56 ],\n",
       "       [131790.83 ],\n",
       "       [270286.5  ],\n",
       "       [149631.66 ],\n",
       "       [217911.89 ],\n",
       "       [180953.67 ],\n",
       "       [ 74582.52 ],\n",
       "       [195784.94 ],\n",
       "       [144731.94 ],\n",
       "       [227556.83 ],\n",
       "       [308008.1  ],\n",
       "       [102572.28 ],\n",
       "       [201828.88 ],\n",
       "       [184776.08 ],\n",
       "       [145244.84 ],\n",
       "       [159211.3  ],\n",
       "       [148351.14 ],\n",
       "       [233468.52 ],\n",
       "       [178451.03 ],\n",
       "       [140824.6  ],\n",
       "       [120715.69 ],\n",
       "       [144890.55 ],\n",
       "       [110498.3  ],\n",
       "       [133819.17 ],\n",
       "       [142886.05 ],\n",
       "       [130830.77 ],\n",
       "       [157072.61 ],\n",
       "       [170597.31 ],\n",
       "       [121008.56 ],\n",
       "       [164719.2  ],\n",
       "       [187379.11 ],\n",
       "       [221408.58 ],\n",
       "       [126987.13 ],\n",
       "       [248723.36 ],\n",
       "       [179914.52 ],\n",
       "       [140894.73 ],\n",
       "       [198529.89 ],\n",
       "       [158511.8  ],\n",
       "       [164827.81 ],\n",
       "       [168198.2  ],\n",
       "       [156936.89 ],\n",
       "       [159964.95 ],\n",
       "       [164346.97 ],\n",
       "       [144036.98 ],\n",
       "       [268536.88 ],\n",
       "       [166954.58 ],\n",
       "       [120456.95 ],\n",
       "       [152186.61 ],\n",
       "       [139201.27 ],\n",
       "       [215094.92 ],\n",
       "       [143444.45 ],\n",
       "       [255451.17 ],\n",
       "       [124618.58 ],\n",
       "       [166057.7  ],\n",
       "       [234628.5  ],\n",
       "       [ 98948.734],\n",
       "       [180260.6  ],\n",
       "       [117324.22 ],\n",
       "       [ 90129.86 ],\n",
       "       [ 91156.47 ],\n",
       "       [310971.12 ],\n",
       "       [153710.14 ],\n",
       "       [357975.47 ],\n",
       "       [133257.36 ],\n",
       "       [133016.53 ],\n",
       "       [166871.47 ],\n",
       "       [199242.3  ],\n",
       "       [170655.27 ],\n",
       "       [121155.57 ],\n",
       "       [118191.1  ],\n",
       "       [298544.88 ],\n",
       "       [141663.23 ],\n",
       "       [151331.52 ],\n",
       "       [262900.44 ],\n",
       "       [161643.86 ],\n",
       "       [121162.2  ],\n",
       "       [159209.86 ],\n",
       "       [158635.73 ],\n",
       "       [157612.73 ],\n",
       "       [126522.22 ],\n",
       "       [146041.8  ],\n",
       "       [ 85255.59 ],\n",
       "       [142599.14 ],\n",
       "       [495460.5  ],\n",
       "       [142421.27 ],\n",
       "       [105167.68 ],\n",
       "       [144148.   ],\n",
       "       [181543.2  ],\n",
       "       [222173.39 ],\n",
       "       [120243.72 ],\n",
       "       [121347.11 ],\n",
       "       [262963.75 ],\n",
       "       [239522.97 ],\n",
       "       [139353.38 ],\n",
       "       [171102.   ],\n",
       "       [145249.36 ],\n",
       "       [137689.14 ],\n",
       "       [ 99733.95 ],\n",
       "       [157576.22 ],\n",
       "       [171641.73 ],\n",
       "       [ 85742.14 ],\n",
       "       [100451.04 ],\n",
       "       [149948.52 ],\n",
       "       [241060.03 ],\n",
       "       [164559.38 ],\n",
       "       [196844.36 ],\n",
       "       [160902.12 ],\n",
       "       [165812.83 ],\n",
       "       [201973.61 ],\n",
       "       [216799.12 ],\n",
       "       [161969.48 ],\n",
       "       [296702.5  ],\n",
       "       [190092.42 ],\n",
       "       [225461.05 ],\n",
       "       [227859.73 ],\n",
       "       [218976.89 ],\n",
       "       [119228.51 ],\n",
       "       [286730.47 ],\n",
       "       [189436.77 ],\n",
       "       [241408.08 ],\n",
       "       [ 84040.69 ],\n",
       "       [200588.58 ],\n",
       "       [252539.39 ],\n",
       "       [247963.81 ],\n",
       "       [252095.61 ],\n",
       "       [168580.78 ],\n",
       "       [222306.39 ],\n",
       "       [117350.555],\n",
       "       [136734.45 ],\n",
       "       [137313.2  ],\n",
       "       [131402.47 ],\n",
       "       [139167.94 ],\n",
       "       [282630.75 ],\n",
       "       [206568.08 ],\n",
       "       [180033.33 ],\n",
       "       [134553.23 ],\n",
       "       [112453.99 ],\n",
       "       [117538.63 ],\n",
       "       [155115.52 ],\n",
       "       [135527.2  ],\n",
       "       [146604.81 ],\n",
       "       [124328.484],\n",
       "       [102571.49 ],\n",
       "       [189175.58 ],\n",
       "       [154225.75 ],\n",
       "       [128742.84 ],\n",
       "       [268279.5  ],\n",
       "       [155723.08 ],\n",
       "       [276088.62 ],\n",
       "       [237482.9  ],\n",
       "       [164683.73 ],\n",
       "       [149185.58 ],\n",
       "       [156164.45 ],\n",
       "       [ 57319.086],\n",
       "       [118735.34 ],\n",
       "       [ 93576.61 ],\n",
       "       [186627.95 ],\n",
       "       [101182.2  ],\n",
       "       [204227.08 ],\n",
       "       [162001.39 ],\n",
       "       [177664.42 ],\n",
       "       [130721.34 ],\n",
       "       [209175.98 ],\n",
       "       [122410.82 ],\n",
       "       [141062.22 ],\n",
       "       [153951.52 ],\n",
       "       [330869.78 ],\n",
       "       [173586.3  ],\n",
       "       [263671.62 ],\n",
       "       [125855.47 ],\n",
       "       [124414.71 ],\n",
       "       [135781.27 ],\n",
       "       [404846.25 ],\n",
       "       [166048.08 ],\n",
       "       [199668.11 ],\n",
       "       [318765.47 ],\n",
       "       [189496.12 ],\n",
       "       [217091.67 ],\n",
       "       [174454.61 ],\n",
       "       [349564.3  ],\n",
       "       [134158.08 ],\n",
       "       [134744.39 ],\n",
       "       [164851.11 ],\n",
       "       [116742.7  ],\n",
       "       [198211.77 ],\n",
       "       [ 79805.53 ],\n",
       "       [ 88898.05 ],\n",
       "       [226169.05 ],\n",
       "       [131338.36 ],\n",
       "       [187779.45 ],\n",
       "       [125035.97 ],\n",
       "       [172793.05 ],\n",
       "       [ 84883.07 ],\n",
       "       [272513.22 ],\n",
       "       [114877.31 ],\n",
       "       [137083.3  ],\n",
       "       [120746.33 ],\n",
       "       [167857.14 ],\n",
       "       [ 81077.195],\n",
       "       [113351.84 ],\n",
       "       [223039.83 ],\n",
       "       [198980.53 ],\n",
       "       [184938.75 ],\n",
       "       [169457.88 ],\n",
       "       [192744.75 ],\n",
       "       [166175.22 ],\n",
       "       [213350.52 ],\n",
       "       [ 99869.64 ],\n",
       "       [185873.12 ],\n",
       "       [340958.75 ],\n",
       "       [133647.4  ],\n",
       "       [151492.86 ],\n",
       "       [305681.34 ],\n",
       "       [143532.19 ],\n",
       "       [118327.98 ],\n",
       "       [157049.11 ],\n",
       "       [199434.48 ],\n",
       "       [292578.25 ],\n",
       "       [238503.4  ],\n",
       "       [117105.41 ],\n",
       "       [ 86376.914],\n",
       "       [313097.72 ],\n",
       "       [278192.12 ],\n",
       "       [106622.56 ],\n",
       "       [ 88825.484],\n",
       "       [166004.44 ],\n",
       "       [163799.97 ],\n",
       "       [204840.7  ],\n",
       "       [281714.97 ],\n",
       "       [308993.72 ],\n",
       "       [126750.65 ],\n",
       "       [437658.84 ],\n",
       "       [125820.13 ],\n",
       "       [123291.695],\n",
       "       [ 90474.45 ],\n",
       "       [181271.88 ],\n",
       "       [195554.3  ],\n",
       "       [177668.23 ],\n",
       "       [124053.266],\n",
       "       [267175.56 ],\n",
       "       [176835.53 ],\n",
       "       [207206.14 ],\n",
       "       [250753.61 ],\n",
       "       [353474.12 ],\n",
       "       [169707.42 ],\n",
       "       [236656.5  ],\n",
       "       [ 97095.234],\n",
       "       [120055.72 ],\n",
       "       [108330.125],\n",
       "       [140724.47 ],\n",
       "       [295176.44 ],\n",
       "       [179221.81 ],\n",
       "       [158977.61 ],\n",
       "       [169233.12 ],\n",
       "       [113800.836],\n",
       "       [125792.88 ],\n",
       "       [159218.81 ],\n",
       "       [ 97155.39 ],\n",
       "       [155621.   ],\n",
       "       [189461.08 ],\n",
       "       [196100.02 ],\n",
       "       [175805.17 ],\n",
       "       [136362.73 ],\n",
       "       [136509.62 ],\n",
       "       [126624.375],\n",
       "       [149022.02 ],\n",
       "       [120029.8  ],\n",
       "       [183330.05 ],\n",
       "       [154092.05 ],\n",
       "       [186922.3  ],\n",
       "       [162400.97 ],\n",
       "       [ 87026.44 ],\n",
       "       [282205.   ],\n",
       "       [158826.67 ],\n",
       "       [216228.11 ],\n",
       "       [ 89729.3  ],\n",
       "       [163185.3  ],\n",
       "       [152943.94 ],\n",
       "       [155515.11 ],\n",
       "       [120406.625],\n",
       "       [157150.92 ],\n",
       "       [107945.266],\n",
       "       [133898.69 ],\n",
       "       [141903.55 ],\n",
       "       [177659.34 ]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict(x_train)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 998us/step - loss: 454568640.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "454568640.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9758</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1103</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnWw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>79.0</td>\n",
       "      <td>8910</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1101          30       RL         60.0     8400   Pave   NaN      Reg   \n",
       "1  1102          20       RL         61.0     9758   Pave   NaN      IR1   \n",
       "2  1103          20       RL         70.0     7000   Pave   NaN      Reg   \n",
       "3  1104          20       RL         79.0     8910   Pave   NaN      Reg   \n",
       "4  1105         160       RM         24.0     2016   Pave   NaN      Reg   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Bnk    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "1         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "2         Lvl    AllPub  ...           0        0    NaN  MnWw         NaN   \n",
       "3         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "4         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0       0      1    2009        WD         Normal  \n",
       "1       0      7    2007        WD         Normal  \n",
       "2       0      4    2007        WD         Family  \n",
       "3       0      7    2006        WD         Normal  \n",
       "4       0      4    2007        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('Test_Data.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.drop(['Id','Alley','PoolQC','MiscFeature'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'Fence', 'SaleType', 'SaleCondition']\n",
      "['MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'Fence']\n",
      "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n"
     ]
    }
   ],
   "source": [
    "#Creating different list of int and object type columns\n",
    "\n",
    "\n",
    "columns = test1.columns\n",
    "test_types = test1.dtypes\n",
    "col_counts = test1.count()\n",
    "\n",
    "N = test1.shape[0]\n",
    "\n",
    "objt_cols = []\n",
    "missing_objt_cols = []\n",
    "missing_numt_cols = []\n",
    "\n",
    "for i in range(test1.shape[1]):  \n",
    "    if test_types[i]=='object' and col_counts[i]!=N:\n",
    "        missing_objt_cols.append(columns[i])\n",
    "        \n",
    "for i in range(test1.shape[1]):        \n",
    "    if test_types[i]=='object':\n",
    "        objt_cols.append(columns[i])\n",
    "        \n",
    "print(objt_cols)\n",
    "print(missing_objt_cols)\n",
    "\n",
    " \n",
    "for j in range(test1.shape[1]):\n",
    "    if (test_types[j]=='int64' or test_types[j]=='float64') and col_counts[j]!=N:\n",
    "        missing_numt_cols.append(columns[j])\n",
    "        \n",
    "print(missing_numt_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling missing values and converting the data in numerical form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in missing_objt_cols:\n",
    "    test1[i].fillna('NAN',inplace=True)\n",
    "    \n",
    "    \n",
    "\n",
    "for j in missing_numt_cols:\n",
    "    test1[j].fillna(test[j].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "cv = CountVectorizer()\n",
    "\n",
    "    \n",
    "for i in objt_cols:\n",
    "    test1[i] = le.fit_transform(test1[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 76)\n"
     ]
    }
   ],
   "source": [
    "X_test = test1.values\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()             #Normalising test data\n",
    "x_test = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 86461.305],\n",
       "       [123998.16 ],\n",
       "       [124823.9  ],\n",
       "       [142026.33 ],\n",
       "       [118573.34 ],\n",
       "       [331858.62 ],\n",
       "       [178142.77 ],\n",
       "       [242775.78 ],\n",
       "       [157000.3  ],\n",
       "       [294141.66 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictions.reshape(x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving our predictions in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Id':test['Id'],\n",
    "                   'SalesPrice':pred})     \n",
    "df.to_csv('House_price_predictions',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9308391290680236"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "score = r2_score(y_train,y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
